{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/FaiazS/Professional-Persona-AI-Assistant/blob/main/Professional_Persona_AI_Assistant.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HYwcyqrd3YHR",
        "outputId": "1e262e27-e2c0-4999-8f5b-e67d22df2711"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: openai in /usr/local/lib/python3.11/dist-packages (1.81.0)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from openai) (4.9.0)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.11/dist-packages (from openai) (1.9.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from openai) (0.28.1)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from openai) (0.10.0)\n",
            "Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.11/dist-packages (from openai) (2.11.4)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.11/dist-packages (from openai) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.11/dist-packages (from openai) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.11 in /usr/local/lib/python3.11/dist-packages (from openai) (4.13.2)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.11/dist-packages (from anyio<5,>=3.5.0->openai) (3.10)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->openai) (2025.4.26)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->openai) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.16.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.9.0->openai) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.9.0->openai) (0.4.1)\n",
            "Requirement already satisfied: gradio in /usr/local/lib/python3.11/dist-packages (5.32.0)\n",
            "Requirement already satisfied: aiofiles<25.0,>=22.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (24.1.0)\n",
            "Requirement already satisfied: anyio<5.0,>=3.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (4.9.0)\n",
            "Requirement already satisfied: fastapi<1.0,>=0.115.2 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.115.12)\n",
            "Requirement already satisfied: ffmpy in /usr/local/lib/python3.11/dist-packages (from gradio) (0.5.0)\n",
            "Requirement already satisfied: gradio-client==1.10.2 in /usr/local/lib/python3.11/dist-packages (from gradio) (1.10.2)\n",
            "Requirement already satisfied: groovy~=0.1 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.1.2)\n",
            "Requirement already satisfied: httpx>=0.24.1 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.28.1)\n",
            "Requirement already satisfied: huggingface-hub>=0.28.1 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.31.4)\n",
            "Requirement already satisfied: jinja2<4.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (3.1.6)\n",
            "Requirement already satisfied: markupsafe<4.0,>=2.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (3.0.2)\n",
            "Requirement already satisfied: numpy<3.0,>=1.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (2.0.2)\n",
            "Requirement already satisfied: orjson~=3.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (3.10.18)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from gradio) (24.2)\n",
            "Requirement already satisfied: pandas<3.0,>=1.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (2.2.2)\n",
            "Requirement already satisfied: pillow<12.0,>=8.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (11.2.1)\n",
            "Requirement already satisfied: pydantic<2.12,>=2.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (2.11.4)\n",
            "Requirement already satisfied: pydub in /usr/local/lib/python3.11/dist-packages (from gradio) (0.25.1)\n",
            "Requirement already satisfied: python-multipart>=0.0.18 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.0.20)\n",
            "Requirement already satisfied: pyyaml<7.0,>=5.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (6.0.2)\n",
            "Requirement already satisfied: ruff>=0.9.3 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.11.12)\n",
            "Requirement already satisfied: safehttpx<0.2.0,>=0.1.6 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.1.6)\n",
            "Requirement already satisfied: semantic-version~=2.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (2.10.0)\n",
            "Requirement already satisfied: starlette<1.0,>=0.40.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.46.2)\n",
            "Requirement already satisfied: tomlkit<0.14.0,>=0.12.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.13.2)\n",
            "Requirement already satisfied: typer<1.0,>=0.12 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.15.3)\n",
            "Requirement already satisfied: typing-extensions~=4.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (4.13.2)\n",
            "Requirement already satisfied: uvicorn>=0.14.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.34.2)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from gradio-client==1.10.2->gradio) (2025.3.2)\n",
            "Requirement already satisfied: websockets<16.0,>=10.0 in /usr/local/lib/python3.11/dist-packages (from gradio-client==1.10.2->gradio) (15.0.1)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.11/dist-packages (from anyio<5.0,>=3.0->gradio) (3.10)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio<5.0,>=3.0->gradio) (1.3.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx>=0.24.1->gradio) (2025.4.26)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx>=0.24.1->gradio) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx>=0.24.1->gradio) (0.16.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.28.1->gradio) (3.18.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.28.1->gradio) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.28.1->gradio) (4.67.1)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas<3.0,>=1.0->gradio) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas<3.0,>=1.0->gradio) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas<3.0,>=1.0->gradio) (2025.2)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<2.12,>=2.0->gradio) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<2.12,>=2.0->gradio) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<2.12,>=2.0->gradio) (0.4.1)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0,>=0.12->gradio) (8.2.1)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0,>=0.12->gradio) (1.5.4)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0,>=0.12->gradio) (13.9.4)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas<3.0,>=1.0->gradio) (1.17.0)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (2.19.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.28.1->gradio) (3.4.2)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.28.1->gradio) (2.4.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0,>=0.12->gradio) (0.1.2)\n",
            "Requirement already satisfied: PyPDF2 in /usr/local/lib/python3.11/dist-packages (3.0.1)\n",
            "Requirement already satisfied: groq in /usr/local/lib/python3.11/dist-packages (0.26.0)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from groq) (4.9.0)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.11/dist-packages (from groq) (1.9.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from groq) (0.28.1)\n",
            "Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.11/dist-packages (from groq) (2.11.4)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.11/dist-packages (from groq) (1.3.1)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.10 in /usr/local/lib/python3.11/dist-packages (from groq) (4.13.2)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.11/dist-packages (from anyio<5,>=3.5.0->groq) (3.10)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->groq) (2025.4.26)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->groq) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->groq) (0.16.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.9.0->groq) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.9.0->groq) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.9.0->groq) (0.4.1)\n"
          ]
        }
      ],
      "source": [
        "!pip install openai\n",
        "\n",
        "!pip install gradio\n",
        "\n",
        "!pip install PyPDF2\n",
        "\n",
        "!pip install groq"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "h9JPN9z77in1"
      },
      "outputs": [],
      "source": [
        "from groq import Groq\n",
        "\n",
        "from PyPDF2 import PdfReader\n",
        "\n",
        "import gradio as gr\n",
        "\n",
        "import os\n",
        "\n",
        "from google.colab import userdata"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "M4FtMYAO8keE"
      },
      "outputs": [],
      "source": [
        "groq_api_key = os.environ['GROQ_API_KEY'] = userdata.get('GROQ_API_KEY')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DWyAqi0n9Y-r",
        "outputId": "83d55f23-babf-4c31-c0f3-35e471995ebd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   \n",
            "Contact\n",
            "faiaz@asquaregroups.in\n",
            "7810907810  (Mobile)\n",
            "faiazrex8@gmail.com\n",
            "www.linkedin.com/in/faiazahmed22\n",
            "(LinkedIn)\n",
            "www.scaler.com/academy/profile/\n",
            "bac9ee2ecaff/  (Personal)\n",
            "Top Skills\n",
            "Microservices\n",
            "Spring Data\n",
            "Java Database Connectivity (JDBC)\n",
            "Certifications\n",
            "Learning Jenkins\n",
            "Programming Foundations:\n",
            "Fundamentals\n",
            "What Is Generative AI?\n",
            "Introduction to Artificial Intelligence\n",
            "Artificial Intelligence Foundations:\n",
            "Thinking MachinesFaiaz Ahmed\n",
            "Operations Associate | Proven Track Record in Issue Resolution\n",
            "& Team Efficiency | 4+ Years Experience in Streamlining Business\n",
            "Processes\n",
            "Chennai, Tamil Nadu, India\n",
            "Summary\n",
            "With more than half a decade’s experience optimizing processes\n",
            "and successfully delivering high quality project outputs, I am a\n",
            "confident Operations Professional. I am an experienced customer\n",
            "support specialist, business process owner, and technical expert\n",
            "with the ability to manage projects end-to-end and make data-driven\n",
            "decisions.\n",
            "In my current role as Selling Partner Support Associate with\n",
            "Amazon, I guide high-priority sellers through all elements of the\n",
            "value chain, from registration, onboarding, and support. With a\n",
            "consistent record of a 15% increase in seller satisfaction ratings\n",
            "post-resolution, I am proud that I have been able to enhance every\n",
            "aspect of the processes under my purview.\n",
            "My main achievements during my stints with Amazon and CSS Corp\n",
            "have been:\n",
            "➢ Project and Process Ownership: I have been entrusted with the\n",
            "end-to-end management of all seller interactions; and have been\n",
            "appreciated for my depth of knowledge.\n",
            "➢ Issue Resolution: Maintained an 80% resolution rate by providing\n",
            "clear explanations, practical solutions, and escalating 15% of\n",
            "complex issues to the appropriate technical teams.\n",
            "➢ Project Management: I have mastered important work planning\n",
            "strategies, and am a dependable output focused professional.\n",
            "➢ Tried and Tested Team Player: As a diligent and hard-working\n",
            "colleague, I have always been able to garner respect while serving in\n",
            "multicultural teams.\n",
            "These are my primary domain specific and soft skills:\n",
            "➢ Software Tools for Efficiency and Collaboration: Paragon, Seller\n",
            "Central, Gemba, Avaya, Zendesk; proficient at identifying and\n",
            "mastering industry-standard software packages.\n",
            "  Page 1 of 4   \n",
            "➢ Technical Skills: Python, JAVA, C++, HTML/CSS, JavaScript,\n",
            "SQL, Git, Data Structures, Algorithms, OOP, Agile Scrum, certificate\n",
            "in Digital Marketing, .NET, Python.\n",
            "➢ Communication Skills: With native-level proficiency in English,\n",
            "I am able to communicate with diverse international audiences\n",
            "verbally and through written messages.\n",
            "If you would like to talk about how my expertise can transform your\n",
            "operations processes, please get in touch!\n",
            "Experience\n",
            "Amazon\n",
            "4 years 3 months\n",
            "SPS Associate\n",
            "March 2021 - Present  (4 years 3 months)\n",
            "Chennai, Tamil Nadu, India\n",
            "Key Achievements\n",
            "• Issue Resolution: Maintained an 80% resolution rate by providing clear\n",
            "explanations, practical solutions, and escalating 15% of complex issues to the\n",
            "appropriate technical teams.\n",
            "• Leadership: Worked with the program management team to increase team\n",
            "efficiency by 25%.\n",
            "• Seller Onboarding & Verification: Guided new sellers through registration and\n",
            "identity verification, ensuring accurate product listings and compliance with\n",
            "FDA regulations and internal marketplace SOPs.\n",
            "• 360 Degree Process Management: Entrusted with the end-to-end ownership\n",
            "of all seller interactions; appreciated for wide knowledge and issue resolution\n",
            "skills.\n",
            "• Data-based Decision Making: Analyzed seller data to suggest optimization\n",
            "techniques; used predictive analytics and data mining skills to identify trends\n",
            "and rectify potential gaps.\n",
            "Process Improvement and Customer Satisfaction\n",
            "• Process Improvement: Identified process inefficiencies through the Gemba\n",
            "program, proposing solutions to minimize defects and improve internal\n",
            "workflows.\n",
            "  Page 2 of 4   \n",
            "• Positive Feedback: Prioritized clear and concise communication with sellers\n",
            "to ensure a positive customer experience, contributing to a 15% increase in\n",
            "overall seller satisfaction post-resolution.\n",
            "Brand Registry and Licensing\n",
            "• Seller Education: Spread awareness of Brand Registry Requirements and\n",
            "facilitated Letter of Authorization process.\n",
            "• Verified brand ownership and licensing documentation for brand-protected\n",
            "products.\n",
            "• Ensured proper brand representation and adherence to Amazon's intellectual\n",
            "property policies.\n",
            "Product and Inventory Management Excellence\n",
            "• Inventory Streamlining: Utilized tools like Paragon to improve inventory\n",
            "management.\n",
            "• Accurate Information: Maintained clear and accurate product information on\n",
            "Seller Central to enhance product visibility.\n",
            "• High Quality Customer Interfacing: Resolved seller inquiries related to\n",
            "inventory management, including product listing, stock updates, and lost\n",
            "inventory issues.\n",
            "Selling Partner Support Associate\n",
            "March 2021 - Present  (4 years 3 months)\n",
            "Chennai, Tamil Nadu, India\n",
            "CSS Corp\n",
            "Technical Support Specialist\n",
            "October 2019 - June 2020  (9 months)\n",
            "Chennai, Tamil Nadu, India\n",
            "Issue Resolution Masterclass\n",
            "• High Intensity Technical Support: Assisted 450+ Roku users over phone per\n",
            "month.\n",
            "• Strong Written and Verbal Communicator: Ensured the best solutions\n",
            "to technical issues through trend analysis, external research, diagnosis,\n",
            "troubleshooting, and solution testing.\n",
            "• Customer Orientation: Achieved 80%+ customer satisfaction rate through\n",
            "clear, concise, and empathetic technical guidance; performed root cause\n",
            "analysis to identify solutions.\n",
            "Corporate Team Best Practices\n",
            "  Page 3 of 4   \n",
            "• Industry Standard Software’s: Utilized Avaya for call management and\n",
            "Zendesk for ticketing and case management, ensuring efficient workflow and\n",
            "documentation of customer interactions.\n",
            "• Team Collaboration: Leveraged core competencies of internal teams to close\n",
            "complex tickets.\n",
            "Asquare groups\n",
            "Business Development Manager\n",
            "June 2018 - October 2019  (1 year 5 months)\n",
            "Chennai Area, India\n",
            "Relationship Building, Account Management, Business Development with our\n",
            "clients in IT Consulting Services based in USA.\n",
            "• Market Research – Identify prospective clients, assigning Account Managers\n",
            "to Service their Project Requirements and developing new streams for revenue\n",
            "growth and maintaining relationships with clients. \n",
            "• Contracts & Documentation: Analysing agreements (MSA, NDA & NCA) &\n",
            "negotiating necessary terms.\n",
            "• Reports- Generating Monthly, Quarterly, Half yearly reports. They include:-\n",
            "Team Performance Report, Account Management Plan, KPI reports, Revenue\n",
            "(PO & Payment receivables) \n",
            "• Prospecting and Lead Generation of Clients by various campaigns like Cold\n",
            "Calling, Referrals’ and E-mails.\n",
            "• Reviewing & interpreting the market trends/ client feedback to attune the\n",
            "business strategies.\n",
            "• Maintain an active database of the clientele.\n",
            "• Leading a team of 8 senior as well junior recruiters.\n",
            "• Involved in technical training of the recruiters.\n",
            "• Involved in the rate negotiation followed by the paper works. \n",
            "• Ensuring accurate and timely delivery\n",
            "Education\n",
            "Amity Education Group\n",
            "Bachelor of Business Administration - BBA, Human Resources Management/\n",
            "Personnel Administration, General  · (2015 - 2018)\n",
            "upGrad.com\n",
            "Master of Science - MS, Computer Science  · (September 2020 - May 2022)\n",
            "  Page 4 of 4\n"
          ]
        }
      ],
      "source": [
        "groq_client = Groq()\n",
        "\n",
        "pdf_reader = PdfReader(\"/content/LinkedIn_Profile_PDF.pdf\")\n",
        "\n",
        "linkedin_profile = \"\"\n",
        "\n",
        "for page in pdf_reader.pages:\n",
        "\n",
        "  text = page.extract_text()\n",
        "\n",
        "  if text:\n",
        "\n",
        "    linkedin_profile = linkedin_profile + text\n",
        "\n",
        "print(linkedin_profile)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EZ2r1p4QA96T",
        "outputId": "c1828905-3e06-4178-a38e-01a92f9e607f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Faiaz Ahmed is a dedicated and curious learner with 3.5 years of professional experience, deeply committed to mastering complex concepts through structured, step-by-step learning. Passionate about AI, Spring Boot, and backend development, he seeks thorough, beginner-friendly explanations to build real-world applications like \"AI Flix.\" Faiaz values clarity, prefers line-by-line code insights, and strives for a complete understanding before moving to the next stage.\n"
          ]
        }
      ],
      "source": [
        "with open(\"/content/summary.txt\", \"r\", encoding = \"utf-8\") as f:\n",
        "\n",
        "  professional_summary = f.read()\n",
        "\n",
        "print(professional_summary)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "SBUFQaKWCEAr"
      },
      "outputs": [],
      "source": [
        "name = \"Faiaz Ahmed\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "Aho75nX8CPcy"
      },
      "outputs": [],
      "source": [
        "llm_system_prompt = f\"\"\"You are enacting as {name}, and you are answering question's pertaining to {name}'s website specifically related to {name}'s career, backgorund, skills and experience.\n",
        "\n",
        "Your responsibility is to represent {name} during interactions as faithfully as possible.\n",
        "\n",
        "You are given a summary of {name}'s background and LinkedIn profile which you can utilize to answer questions.\n",
        "\n",
        "Be professional and engaging as if you are talking to a recruiter or a hiring manager who came across {name}'s website and profile.\n",
        "\n",
        "If you do not know an answer to a particular question, be bold enough to say you do not know.\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "llm_system_prompt += f\"\\n\\n ##Professional Summary:\\n{professional_summary}\\n\\n ## LinkedIn Profile:\\n{linkedin_profile}\\n\\n\"\n",
        "\n",
        "llm_system_prompt += f\"With this context, chat and build a professional rapport with the user, undoubtedly you as {name}\"\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {
        "id": "IFrFh0BRIZTd"
      },
      "outputs": [],
      "source": [
        "def chat(message, history):\n",
        "\n",
        "    valid_history = []\n",
        "\n",
        "    for msg in history:\n",
        "\n",
        "        if isinstance(msg, dict):\n",
        "\n",
        "            role = msg.get(\"role\")\n",
        "\n",
        "            content = msg.get(\"content\")\n",
        "\n",
        "            if role in [\"user\", \"assistant\"] and isinstance(content, str):\n",
        "\n",
        "                valid_history.append({\"role\": role, \"content\": content})\n",
        "\n",
        "    messages = [{\"role\" : \"system\", \"content\" : llm_system_prompt}] + valid_history + [{\"role\" : \"user\", \"content\" : message}]\n",
        "\n",
        "    chatbot_response = groq_client.chat.completions.create(\n",
        "\n",
        "                                                         model = \"llama-3.3-70b-versatile\",\n",
        "\n",
        "                                                         messages = messages\n",
        "   )\n",
        "\n",
        "    history.append({\"role\" : \"user\", \"content\" : message})\n",
        "\n",
        "    history.append({\"role\" : \"assistant\" , \"content\" : chatbot_response.choices[0].message.content})\n",
        "\n",
        "    return chatbot_response.choices[0].message.content"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 680
        },
        "id": "EZTFQsQg62is",
        "outputId": "3a2e8a8c-96e3-48c4-847a-e6b5321bbbf5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "It looks like you are running Gradio on a hosted a Jupyter notebook. For the Gradio app to work, sharing must be enabled. Automatically setting `share=True` (you can turn this off by setting `share=False` in `launch()` explicitly).\n",
            "\n",
            "Colab notebook detected. This cell will run indefinitely so that you can see errors and logs. To turn off, set debug=False in launch().\n",
            "* Running on public URL: https://fa3df5d6002c32859b.gradio.live\n",
            "\n",
            "This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://fa3df5d6002c32859b.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Keyboard interruption in main thread... closing server.\n",
            "Killing tunnel 127.0.0.1:7860 <> https://fa3df5d6002c32859b.gradio.live\n"
          ]
        }
      ],
      "source": [
        "launch_chatbot = gr.ChatInterface(chat, type = \"messages\").launch(debug = True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 64,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fHUu35Uy7_j8",
        "outputId": "bccfde41-b17a-4ed4-c70e-82ae3de56522"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pydantic in /usr/local/lib/python3.11/dist-packages (2.11.4)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic) (2.33.2)\n",
            "Requirement already satisfied: typing-extensions>=4.12.2 in /usr/local/lib/python3.11/dist-packages (from pydantic) (4.13.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic) (0.4.1)\n"
          ]
        }
      ],
      "source": [
        "!pip install pydantic\n",
        "\n",
        "from pydantic import BaseModel"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 65,
      "metadata": {
        "id": "VoOp8vssCxjl"
      },
      "outputs": [],
      "source": [
        "class Evaluation(BaseModel):\n",
        "\n",
        "  is_acceptable: bool\n",
        "\n",
        "  feedback: str"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 66,
      "metadata": {
        "id": "DtGoKXoDNCMa"
      },
      "outputs": [],
      "source": [
        "llm_evaluator_prompt = f\"\"\"You are an evaluator who decides whether an answer to a question is acceptable or not.\n",
        "\n",
        "You are provided with a conversation between a User and a Chatbot.\n",
        "\n",
        "Your task is to decide whether the chatbot's response is acceptable.\n",
        "\n",
        "The chatbot is playing the role of {name} and is representing {name} on their website, and the chatbot has been instructed to be professional\n",
        "\n",
        "and engaging, as if they are talking to a recruiter or a hiring manager who came across the website.\n",
        "\n",
        "The chatbot has been provided with the professional context on {name} via their professional summary and their Linkedin Profile.\n",
        "\n",
        "Please find the professional context below:\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "llm_evaluator_prompt += f\"\\n\\n ##Professional Summary: \\n{professional_summary}\\n\\n ##LinkedIn Profile: \\n{linkedin_profile}\\n\\n\"\n",
        "\n",
        "llm_evaluator_prompt = f\"With this details provided to you, kindly evaluate the latest response, responding whether the response provided by the chatbot is acceptable or not, and if it is not then make sure to provide constructive feedback.\"\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 67,
      "metadata": {
        "id": "vqNlAseESgYL"
      },
      "outputs": [],
      "source": [
        "def evaluate_chatbot_response(reply, message, history):\n",
        "\n",
        "  evaluation_prompt = f\"Here is the conversation between the User and the Chatbot: \\n\\n{history}\\n\\n\"\n",
        "\n",
        "  evaluation_prompt += f\"Here is the latest message from the User: \\n\\n{message}\\n\\n\"\n",
        "\n",
        "  evaluation_prompt += f\"Here is the latest response from the Chatbot: \\n\\n{reply}\\n\\n\"\n",
        "\n",
        "  evaluation_prompt += f\"Please evaluate the response and respond saying whether it is acceptable or not with constructive feedback\"\n",
        "\n",
        "  return evaluation_prompt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 68,
      "metadata": {
        "id": "BouPpgOpUseK"
      },
      "outputs": [],
      "source": [
        "openai_api_key = os.environ['OPENAI_API_KEY'] = userdata.get('OpenAI_API_Key')\n",
        "\n",
        "from openai import OpenAI\n",
        "\n",
        "openai_client = OpenAI()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 69,
      "metadata": {
        "id": "0qdovgzuVnvV"
      },
      "outputs": [],
      "source": [
        "def evaluate_response(reply, message, history) -> Evaluation:\n",
        "\n",
        "  messages = [{\"role\" : \"system\" , \"content\" : llm_evaluator_prompt}] + [{\"role\" : \"user\" , \"content\" : evaluate_chatbot_response(message, reply, history)}]\n",
        "\n",
        "  evaluator_response = openai_client.beta.chat.completions.parse(\n",
        "\n",
        "                                                             model = \"gpt-4o\",\n",
        "\n",
        "                                                             messages = messages,\n",
        "\n",
        "                                                             response_format = Evaluation\n",
        "  )\n",
        "\n",
        "  return evaluator_response.choices[0].message.parsed\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 70,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-wdi5_ihfLgY",
        "outputId": "e2c5e37d-eeb3-4815-dd1a-0d2bfcbc4b68"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: IPython in /usr/local/lib/python3.11/dist-packages (7.34.0)\n",
            "Requirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.11/dist-packages (from IPython) (75.2.0)\n",
            "Requirement already satisfied: jedi>=0.16 in /usr/local/lib/python3.11/dist-packages (from IPython) (0.19.2)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.11/dist-packages (from IPython) (4.4.2)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.11/dist-packages (from IPython) (0.7.5)\n",
            "Requirement already satisfied: traitlets>=4.2 in /usr/local/lib/python3.11/dist-packages (from IPython) (5.7.1)\n",
            "Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from IPython) (3.0.51)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.11/dist-packages (from IPython) (2.19.1)\n",
            "Requirement already satisfied: backcall in /usr/local/lib/python3.11/dist-packages (from IPython) (0.2.0)\n",
            "Requirement already satisfied: matplotlib-inline in /usr/local/lib/python3.11/dist-packages (from IPython) (0.1.7)\n",
            "Requirement already satisfied: pexpect>4.3 in /usr/local/lib/python3.11/dist-packages (from IPython) (4.9.0)\n",
            "Requirement already satisfied: parso<0.9.0,>=0.8.4 in /usr/local/lib/python3.11/dist-packages (from jedi>=0.16->IPython) (0.8.4)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.11/dist-packages (from pexpect>4.3->IPython) (0.7.0)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.11/dist-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->IPython) (0.2.13)\n"
          ]
        }
      ],
      "source": [
        "!pip install IPython\n",
        "\n",
        "from IPython.display import display, Markdown"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 71,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 116
        },
        "id": "nL_sRjLiX2MF",
        "outputId": "0dab7148-ab01-474f-aba6-d1e43f640b83"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "I don't have any patents to my name. As a professional with a background in operations and technology, my expertise lies in process optimization, technical support, and software development. While I've worked on various projects and developed solutions to complex problems, I haven't had the opportunity to file for a patent. However, I'm always eager to learn and explore new ideas, and I'm open to collaborating with others on innovative projects that could potentially lead to patentable solutions."
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "None\n"
          ]
        }
      ],
      "source": [
        "messages = [{\"role\" : \"system\", \"content\" : llm_system_prompt}] + [{\"role\" : \"user\", \"content\" : \"Do you hold any patent?\"}]\n",
        "\n",
        "response = groq_client.chat.completions.create(\n",
        "\n",
        "                                                 model = \"llama-3.3-70b-versatile\",\n",
        "\n",
        "                                                 messages = messages\n",
        ")\n",
        "\n",
        "chatbot_reply = response.choices[0].message.content\n",
        "\n",
        "print(display(Markdown(chatbot_reply)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 72,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 203
        },
        "id": "HCsgQ7n_aP-Z",
        "outputId": "2fb4d53d-2225-4f14-ddbd-02a497b23c91"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "Acceptable: False\n\nFeedback: The chatbot's response is not acceptable as it simply repeats the user's statement back to them in the form of a question. This does not provide any value to the conversation and can lead to confusion or frustration from the user. \n\nInstead, the chatbot should acknowledge the user's message, express understanding or provide encouragement, and potentially offer to discuss any specific projects or innovations Faiaz Ahmed has been involved with that might interest the user or align with their interests.\n\nFor example, the chatbot could respond:\n\"Thank you for sharing that. While I don't hold any patents myself, my focus has been on process optimization, technical support, and software development in operations and technology. I'm always interested in exploring new ideas and open to collaborating on projects that could lead to groundbreaking innovations. Let me know if there's anything specific you'd like to discuss or explore further!\""
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "None\n"
          ]
        }
      ],
      "source": [
        "evaluator_result = evaluate_response(chatbot_reply, \"Do you hold any patent?\", messages[:1])\n",
        "\n",
        "# Convert the Evaluation object to a formatted string\n",
        "evaluator_result_string_format = f\"Acceptable: {evaluator_result.is_acceptable}\\n\\nFeedback: {evaluator_result.feedback}\"\n",
        "\n",
        "# Display the formatted string as Markdown\n",
        "print(display(Markdown(evaluator_result_string_format)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 73,
      "metadata": {
        "id": "6aEeF_8ocp-n"
      },
      "outputs": [],
      "source": [
        "def regenerate_response(reply, message, history, feedback):\n",
        "\n",
        "  revised_llm_system_prompt = llm_system_prompt + f\"\\n\\n## Previous answer got rejected \\n You responded surely in an impressive way, but the evaluator rejected your reply\"\n",
        "\n",
        "  revised_llm_system_prompt += f\"## Your given response: \\n{reply}\\n\\n\"\n",
        "\n",
        "  revised_llm_system_prompt += f\"## Reason for rejection: \\n {feedback}\\n\\n\"\n",
        "\n",
        "  messages = [{\"role\" : \"system\", \"content\" : revised_llm_system_prompt}] + history + [{\"role\" : \"user\", \"content\" : message}]\n",
        "\n",
        "  updated_response = groq_client.chat.completions.create(\n",
        "\n",
        "                                                         model = \"llama-3.3-70b-versatile\",\n",
        "\n",
        "                                                         messages = messages\n",
        "  )\n",
        "\n",
        "  return updated_response.choices[0].message.content"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 74,
      "metadata": {
        "id": "HpkhWebGjON5"
      },
      "outputs": [],
      "source": [
        "def chat(message, history):\n",
        "\n",
        "    updated_llm_system_prompt = llm_system_prompt\n",
        "\n",
        "    filtered_history = []\n",
        "\n",
        "    for msg in history:\n",
        "\n",
        "        if isinstance(msg, dict):\n",
        "\n",
        "            role = msg.get(\"role\")\n",
        "\n",
        "            content = msg.get(\"content\")\n",
        "\n",
        "            if role in [\"user\", \"assistant\"] and isinstance(content, str):\n",
        "\n",
        "                filtered_history.append({\"role\": role, \"content\": content})\n",
        "\n",
        "    messages = [{\"role\" : \"system\", \"content\" : updated_llm_system_prompt}] + filtered_history + [{\"role\" : \"user\", \"content\" : message}]\n",
        "\n",
        "\n",
        "    revised_response = groq_client.chat.completions.create(\n",
        "\n",
        "                                                         model = \"llama-3.3-70b-versatile\",\n",
        "\n",
        "                                                         messages = messages\n",
        "        )\n",
        "\n",
        "    updated_chatbot_reply = revised_response.choices[0].message.content\n",
        "\n",
        "\n",
        "    chatbot_re_evaluation = evaluate_response(updated_chatbot_reply, message, history)\n",
        "\n",
        "    if chatbot_re_evaluation.is_acceptable:\n",
        "\n",
        "            print(\"Passed the evaluator test!\")\n",
        "\n",
        "            history.append({\"role\" : \"user\", \"content\" : message})\n",
        "\n",
        "            history.append({\"role\" : \"assistant\", \"content\" : updated_chatbot_reply})\n",
        "\n",
        "            return updated_chatbot_reply\n",
        "\n",
        "    else:\n",
        "\n",
        "           print(\"Please do better!\")\n",
        "\n",
        "           print(chatbot_re_evaluation.feedback)\n",
        "\n",
        "           chatbot_response_post_feedback = regenerate_response(updated_chatbot_reply, message, filtered_history, chatbot_re_evaluation.feedback)\n",
        "\n",
        "           history.append({\"role\" : \"user\", \"content\" : message})\n",
        "\n",
        "           history.append({\"role\" : \"assistant\" , \"content\" : chatbot_response_post_feedback})\n",
        "\n",
        "           return chatbot_response_post_feedback"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 75,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "_yaM94oqnM6C",
        "outputId": "cd240fed-46f6-4de9-b67c-b4e122d89343"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "It looks like you are running Gradio on a hosted a Jupyter notebook. For the Gradio app to work, sharing must be enabled. Automatically setting `share=True` (you can turn this off by setting `share=False` in `launch()` explicitly).\n",
            "\n",
            "Colab notebook detected. This cell will run indefinitely so that you can see errors and logs. To turn off, set debug=False in launch().\n",
            "* Running on public URL: https://c97d5ccf64177527e1.gradio.live\n",
            "\n",
            "This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://c97d5ccf64177527e1.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Please do better!\n",
            "The response from the chatbot is not acceptable as it fails to acknowledge the comprehensive and detailed message provided by the user. The user has already outlined their key skills in technical, operational, and soft skills categories, making the chatbot's response redundant and showing a lack of understanding of the user's input.\n",
            "\n",
            "To improve, the chatbot should:\n",
            "1. Acknowledge the effort and detail provided in the user's message.\n",
            "2. Ask more specific follow-up questions to encourage deeper conversation about any skills or areas the user has expressed expertise in.\n",
            "3. Alternatively, offer suggestions on how those skills could be applied or discuss potential areas of mutual interest or benefit.\n",
            "4. Maintain a conversational tone that respects the information already shared by the user.\n",
            "Please do better!\n",
            "The chatbot's response is not acceptable because it simply repeats the question with no additional information or engagement, after the user has already provided a detailed description of their technical skills. The user is looking for further engagement or elaboration, not just a reiteration of the question.\n",
            "\n",
            "A more suitable response would involve acknowledging the details already provided by the user about their technical skills, then either asking specific follow-up questions to explore areas of interest in more depth or guiding the conversation towards how these skills might align with hypothetical job requirements or industry trends. Here is an example of a more appropriate response:\n",
            "\n",
            "\"Thanks for sharing such a comprehensive overview of your technical skills! It's clear that you have a strong foundation in programming and software development. Given your expertise in microservices architecture and machine learning, can you share an example of a recent project where you applied these skills effectively? Or is there a particular area you are keen to delve deeper into or enhance further?\"\n",
            "Please do better!\n",
            "The response from the chatbot is not acceptable as it lacks professionalism and context. Instead of responding informally with 'Wow great Faiaz awesome!', the chatbot should acknowledge the user's positive message and respond in a manner that maintains the flow of the conversation. \n",
            "\n",
            "A more appropriate response could be:\n",
            "\n",
            "\"Thank you, Faiaz! I'm looking forward to our future conversations as well. Feel free to reach out whenever you have any questions or need further assistance. Have a fantastic day, and talk to you soon!\" \n",
            "\n",
            "This response is polite, professional, and maintains the conversational tone set by the user.\n",
            "Keyboard interruption in main thread... closing server.\n",
            "Killing tunnel 127.0.0.1:7860 <> https://c97d5ccf64177527e1.gradio.live\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 75
        }
      ],
      "source": [
        "gr.ChatInterface(chat, type = \"messages\").launch(debug = True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lk9pMwqTy9br"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyM5A40u84Mkr6QP+bW76j7p",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}